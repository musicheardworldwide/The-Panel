# OpenAI API Key (required for hosted models)
OPENAI_API_KEY=your_openai_api_key_here

# Model Configuration
# Set to "true" to use a local model like Ollama
USE_LOCAL_MODEL=false

# Hosted Model Settings (used when USE_LOCAL_MODEL=false)
MODEL_NAME=gpt-4o
CONTEXT_WINDOW=10000
MAX_TOKENS=4096

# Local Model Settings (used when USE_LOCAL_MODEL=true)
LOCAL_MODEL_NAME=ollama/llama3.1
LOCAL_API_BASE=http://localhost:11434
LOCAL_CONTEXT_WINDOW=4000
LOCAL_MAX_TOKENS=3000

# Logging and Debug
VERBOSE=false

# Flask Server Configuration
FLASK_HOST=0.0.0.0
FLASK_PORT=5001
FLASK_DEBUG=false